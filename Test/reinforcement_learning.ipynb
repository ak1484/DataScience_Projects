{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected action: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, num_states, num_actions, learning_rate=0.1, discount_factor=0.9):\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.Q = np.zeros((num_states, num_actions))\n",
    "\n",
    "    def update_Q(self, state, action, reward, next_state):\n",
    "        max_next_action_value = np.max(self.Q[next_state])\n",
    "        self.Q[state, action] = (1 - self.learning_rate) * self.Q[state, action] + \\\n",
    "                                self.learning_rate * (reward + self.discount_factor * max_next_action_value)\n",
    "\n",
    "    def select_action(self, state, epsilon):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            return np.argmax(self.Q[state])\n",
    "\n",
    "# Example usage\n",
    "# Define environment parameters\n",
    "num_states = 5\n",
    "num_actions = 2\n",
    "# Create Q-learning agent\n",
    "agent = QLearningAgent(num_states, num_actions)\n",
    "# Update Q-values based on experience\n",
    "state = 0\n",
    "action = 1\n",
    "reward = 1\n",
    "next_state = 1\n",
    "agent.update_Q(state, action, reward, next_state)\n",
    "# Select action using epsilon-greedy strategy\n",
    "state = 1\n",
    "epsilon = 0.1\n",
    "selected_action = agent.select_action(state, epsilon)\n",
    "print(\"Selected action:\", selected_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.0-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.3.0 (from torchvision)\n",
      "  Using cached torch-2.3.0-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torch==2.3.0->torchvision) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch==2.3.0->torchvision)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision)\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "Using cached torchvision-0.18.0-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Using cached torch-2.3.0-cp310-cp310-win_amd64.whl (159.8 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Installing collected packages: tbb, intel-openmp, mkl, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed intel-openmp-2021.4.0 mkl-2021.4.0 tbb-2021.12.0 torch-2.3.0 torchvision-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7843, 0.8235, 0.8314,  ..., 0.2667, 0.5529, 0.6745],\n",
       "         [0.8275, 0.8392, 0.8353,  ..., 0.3686, 0.7843, 0.8588],\n",
       "         [0.8431, 0.8314, 0.8353,  ..., 0.6588, 0.8784, 0.8784],\n",
       "         ...,\n",
       "         [0.8824, 0.8745, 0.8863,  ..., 0.8275, 0.8941, 0.8941],\n",
       "         [0.8510, 0.8627, 0.8745,  ..., 0.8431, 0.9020, 0.8980],\n",
       "         [0.6627, 0.6706, 0.7804,  ..., 0.8941, 0.8980, 0.8980]],\n",
       "\n",
       "        [[0.3059, 0.3216, 0.3294,  ..., 0.2706, 0.4667, 0.5608],\n",
       "         [0.3216, 0.3294, 0.3373,  ..., 0.3216, 0.6549, 0.7137],\n",
       "         [0.3216, 0.3294, 0.3333,  ..., 0.5608, 0.7176, 0.7176],\n",
       "         ...,\n",
       "         [0.7490, 0.7451, 0.7373,  ..., 0.5020, 0.7412, 0.7412],\n",
       "         [0.6863, 0.7020, 0.7294,  ..., 0.5569, 0.7451, 0.7451],\n",
       "         [0.3765, 0.3882, 0.5961,  ..., 0.6824, 0.7373, 0.7412]],\n",
       "\n",
       "        [[0.2196, 0.2353, 0.2314,  ..., 0.2196, 0.3608, 0.4392],\n",
       "         [0.2314, 0.2353, 0.2353,  ..., 0.2431, 0.5137, 0.5529],\n",
       "         [0.2235, 0.2275, 0.2314,  ..., 0.4392, 0.5529, 0.5373],\n",
       "         ...,\n",
       "         [0.5804, 0.5765, 0.5765,  ..., 0.4000, 0.5804, 0.5882],\n",
       "         [0.5333, 0.5490, 0.5686,  ..., 0.4392, 0.5843, 0.5922],\n",
       "         [0.2824, 0.2902, 0.4588,  ..., 0.5373, 0.5765, 0.5882]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(\"itichi.jpg\")\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "])\n",
    "\n",
    "# Apply the transformation to the image\n",
    "tensor_image = transform(image)\n",
    "\n",
    "tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8275, 0.8392, 0.8353, 0.8353, 0.8196, 0.8196, 0.8157, 0.8118, 0.8000,\n",
       "        0.8039, 0.7961, 0.7922, 0.7922, 0.8000, 0.8118, 0.8314, 0.8353, 0.8235,\n",
       "        0.8314, 0.8118, 0.8196, 0.8275, 0.8196, 0.8000, 0.8157, 0.8235, 0.8235,\n",
       "        0.8235, 0.8275, 0.7216, 0.3412, 0.1961, 0.1725, 0.1922, 0.1843, 0.1804,\n",
       "        0.1137, 0.0863, 0.0863, 0.0824, 0.0745, 0.0824, 0.0863, 0.1412, 0.3451,\n",
       "        0.3882, 0.3294, 0.2902, 0.2549, 0.2275, 0.4275, 0.8039, 0.8353, 0.8353,\n",
       "        0.8431, 0.8392, 0.8431, 0.8471, 0.8471, 0.8549, 0.8627, 0.8627, 0.8627,\n",
       "        0.8588, 0.5686, 0.2039, 0.1804, 0.1843, 0.1843, 0.1882, 0.1882, 0.1882,\n",
       "        0.1882, 0.1882, 0.1882, 0.1882, 0.1882, 0.1843, 0.1882, 0.1882, 0.1843,\n",
       "        0.1804, 0.1804, 0.1804, 0.1843, 0.1804, 0.1843, 0.1843, 0.1882, 0.1882,\n",
       "        0.1882, 0.1882, 0.1882, 0.1922, 0.1922, 0.1922, 0.1882, 0.1882, 0.1843,\n",
       "        0.1882, 0.1882, 0.1882, 0.1882, 0.1843, 0.1882, 0.1882, 0.1843, 0.1804,\n",
       "        0.1843, 0.1843, 0.3137, 0.4980, 0.3216, 0.4471, 0.6275, 0.7490, 0.7569,\n",
       "        0.6353, 0.3725, 0.2745, 0.4314, 0.7098, 0.8196, 0.8353, 0.8196, 0.7961,\n",
       "        0.8157, 0.7176, 0.5686, 0.4784, 0.4157, 0.2902, 0.1922, 0.2275, 0.4745,\n",
       "        0.7882, 0.8078, 0.8000, 0.6706, 0.2353, 0.1451, 0.4000, 0.5765, 0.5255,\n",
       "        0.6745, 0.5255, 0.3686, 0.4549, 0.6902, 0.7961, 0.6667, 0.2510, 0.4353,\n",
       "        0.5882, 0.6039, 0.4706, 0.2510, 0.2745, 0.1725, 0.1686, 0.2353, 0.2627,\n",
       "        0.1725, 0.1804, 0.2157, 0.1961, 0.1725, 0.1176, 0.1098, 0.1529, 0.5882,\n",
       "        0.6980, 0.4941, 0.2745, 0.1882, 0.2000, 0.2745, 0.4118, 0.5176, 0.5255,\n",
       "        0.4863, 0.5373, 0.4824, 0.2275, 0.2667, 0.3882, 0.6392, 0.4706, 0.4431,\n",
       "        0.4706, 0.7137, 0.8745, 0.8863, 0.6824, 0.6118, 0.8706, 0.8824, 0.8745,\n",
       "        0.8745, 0.8667, 0.8784, 0.8627, 0.8667, 0.8706, 0.8706, 0.8706, 0.8863,\n",
       "        0.8745, 0.7882, 0.4471, 0.2235, 0.2706, 0.2706, 0.2431, 0.2863, 0.4078,\n",
       "        0.7725, 0.7804, 0.5451, 0.3451, 0.2627, 0.3686, 0.7843, 0.8588])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "def solve(incoming: str) -> int:\n",
    "    # Parse input\n",
    "    lines = incoming.strip().splitlines()\n",
    "    dictionary = set()\n",
    "    encrypted_message = \"\"\n",
    "\n",
    "    # Separate dictionary from encrypted message\n",
    "    for line in lines:\n",
    "        if line == \"#\":\n",
    "            break\n",
    "        dictionary.add(line)\n",
    "    \n",
    "    encrypted_message = lines[len(dictionary) + 1]  # The line after the dictionary\n",
    "\n",
    "    def decrypt(message: str, k: int) -> str:\n",
    "        decrypted = []\n",
    "        for char in message:\n",
    "            if char == ' ':\n",
    "                original_position = 1  # Space position is treated as 0\n",
    "            else:\n",
    "                original_position = ord(char) - ord('A') + 1  # A=1, ..., Z=26\n",
    "\n",
    "            # Calculate new position, wrapping around using modulo 27\n",
    "            new_position = (original_position - k) % 27\n",
    "            \n",
    "            if new_position == 0:\n",
    "                decrypted.append(' ')  # 0 maps back to space\n",
    "            else:\n",
    "                decrypted.append(chr(new_position - 1 + ord('A')))  # Convert back to char\n",
    "\n",
    "        return ''.join(decrypted)\n",
    "\n",
    "    max_matches = 0\n",
    "    best_k = 0\n",
    "\n",
    "    # Check all possible values of K (0 to 26)\n",
    "    for k in range(27):\n",
    "        decrypted_message = decrypt(encrypted_message, k)\n",
    "        words = decrypted_message.split()\n",
    "        matches = sum(1 for word in words if word in dictionary)\n",
    "\n",
    "        if matches > max_matches:\n",
    "            max_matches = matches\n",
    "            best_k = k\n",
    "\n",
    "    return 27-best_k\n",
    "\n",
    "# Example usage:\n",
    "input_data = \"\"\"WHO\\nLET\\nTHE\\nDOGS\\nOUT\\n#\\nIUAMPAGYQM AFMYVXRMQATE\"\"\"\n",
    "\n",
    "print(solve(input_data))  # Should output the correct K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(solve(\"THIS\\nDAWN\\nTHAT\\nTHE\\nZORRO\\nOTHER\\nAT\\nTHING\\n#\\nBUUBDLA PSSPABUAEBXO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "def word_combinations(words, length):\n",
    "    # Generate all combinations of words of given length\n",
    "    return combinations(words, length)\n",
    "\n",
    "def can_form_phrase(phrase_counter, words):\n",
    "    # Count the total letters in the selected words\n",
    "    combined_counter = Counter()\n",
    "    for word in words:\n",
    "        combined_counter += Counter(word)\n",
    "    \n",
    "    return combined_counter == phrase_counter\n",
    "\n",
    "def find_anagrams(dictionary: List[str], phrase: str) -> List[List[str]]:\n",
    "    phrase_counter = Counter(phrase.replace(\" \", \"\"))\n",
    "    results = []\n",
    "    \n",
    "    # Check all combinations of words of various lengths\n",
    "    for r in range(1, len(dictionary) + 1):\n",
    "        for combo in word_combinations(dictionary, r):\n",
    "            if can_form_phrase(phrase_counter, combo):\n",
    "                results.append(list(combo))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def solve(input: str) -> Dict[str, List[List[str]]]:\n",
    "    sections = input.split('#')\n",
    "    dictionary_section = sections[0].strip().splitlines()\n",
    "    phrases_section = sections[1].strip().splitlines()\n",
    "    \n",
    "    # Clean up sections\n",
    "    dictionary = [word.strip() for word in dictionary_section if word.strip()]\n",
    "    phrases = [phrase.strip() for phrase in phrases_section if phrase.strip()]\n",
    "    \n",
    "    # Prepare the result dictionary\n",
    "    result = {}\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        anagrams = find_anagrams(dictionary, phrase)\n",
    "        if anagrams:\n",
    "            result[phrase] = anagrams\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ATRAPS': [['SPARTA']], 'ATRAPS SI': [['IS', 'SPARTA']], 'THIS IS SPARTA': [['IS', 'THIS', 'SPARTA']]}\n"
     ]
    }
   ],
   "source": [
    "print(solve(\"\"\"IS\n",
    "\n",
    "THIS\n",
    "\n",
    "SPARTA\n",
    "\n",
    "#\n",
    "\n",
    "ATRAPS\n",
    "\n",
    "ATRAPS SI\n",
    "\n",
    "THIS IS SPARTA#\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mailtrap\n",
      "  Downloading mailtrap-2.0.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from mailtrap) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from requests>=2.26.0->mailtrap) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from requests>=2.26.0->mailtrap) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from requests>=2.26.0->mailtrap) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ankit\\miniconda3\\envs\\data_science\\lib\\site-packages (from requests>=2.26.0->mailtrap) (2024.2.2)\n",
      "Downloading mailtrap-2.0.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: mailtrap\n",
      "Successfully installed mailtrap-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mailtrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Mail in module mailtrap.mail.mail:\n",
      "\n",
      "class Mail(mailtrap.mail.base.BaseMail)\n",
      " |  Mail(sender: mailtrap.mail.address.Address, to: List[mailtrap.mail.address.Address], subject: str, text: Optional[str] = None, html: Optional[str] = None, category: Optional[str] = None, cc: Optional[List[mailtrap.mail.address.Address]] = None, bcc: Optional[List[mailtrap.mail.address.Address]] = None, attachments: Optional[List[mailtrap.mail.attachment.Attachment]] = None, headers: Optional[Dict[str, str]] = None, custom_variables: Optional[Dict[str, Any]] = None) -> None\n",
      " |  \n",
      " |  Creates a request body for /api/send Mailtrap API v2 endpoint.\n",
      " |  \n",
      " |  Either `text` or `html` param must be specified. You can also\n",
      " |  provide both of them.\n",
      " |  \n",
      " |  If only `text` is provided, `EmailWithText` body type will be used.\n",
      " |  If only `html` is provided, `HtmlWithText` body type will be used.\n",
      " |  If both `text` and `html` are provided,\n",
      " |      `EmailWithTextAndHtml` body type will be used.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Mail\n",
      " |      mailtrap.mail.base.BaseMail\n",
      " |      mailtrap.mail.base_entity.BaseEntity\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sender: mailtrap.mail.address.Address, to: List[mailtrap.mail.address.Address], subject: str, text: Optional[str] = None, html: Optional[str] = None, category: Optional[str] = None, cc: Optional[List[mailtrap.mail.address.Address]] = None, bcc: Optional[List[mailtrap.mail.address.Address]] = None, attachments: Optional[List[mailtrap.mail.attachment.Attachment]] = None, headers: Optional[Dict[str, str]] = None, custom_variables: Optional[Dict[str, Any]] = None) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  api_data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from mailtrap.mail.base.BaseMail:\n",
      " |  \n",
      " |  get_api_data_from_list(items: Optional[Sequence[mailtrap.mail.base_entity.BaseEntity]]) -> Optional[List[Dict[str, Any]]]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from mailtrap.mail.base_entity.BaseEntity:\n",
      " |  \n",
      " |  omit_none_values(data: Dict[str, Any]) -> Dict[str, Any]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from mailtrap.mail.base_entity.BaseEntity:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mailtrap as mt\n",
    "\n",
    "# create mail object\n",
    "mail = mt.Mail(\n",
    "    sender=mt.Address(email=\"mailtrap@example.com\", name=\"Mailtrap Test\"),\n",
    "    to=[mt.Address(email=\"ankitsaharan1484@gmail.com\")],\n",
    "    subject=\"You are awesome!\",\n",
    "    text=\"Congrats for sending test email with Mailtrap!\",\n",
    ")\n",
    "\n",
    "# create client and send\n",
    "client = mt.MailtrapClient(token=\"2297ce278212a371e570776342011be6\")\n",
    "# help(mt.Mail)\n",
    "client.send(mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_func(array):\n",
    "    array = iter(array)\n",
    "    try:\n",
    "        first = next(array)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "some_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message logged successfully\n"
     ]
    }
   ],
   "source": [
    "def log_message(filename, message):\n",
    "    try:\n",
    "        handle = open(filename, 'a')  # Open the file in append mode\n",
    "        handle.write(message)\n",
    "    except Exception as e:\n",
    "        # Handle the exception (e.g., log the error, print an error message, etc.)\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        # Code to execute if no exceptions occur (optional)\n",
    "        print(\"Message logged successfully\")\n",
    "    finally:\n",
    "        # Ensure the file handle is closed properly\n",
    "        handle.close()\n",
    "\n",
    "# Example usage\n",
    "log_message('logfile.txt', 'This is a log message.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='**Solution**\\n```python\\ndef length_of_last_word(s):\\n    \"\"\"\\n    Returns the length of the last word in a given string.\\n\\n    :param s: A string consisting of words and spaces.\\n    :return: The length of the last word.\\n    \"\"\"\\n    # Split the string into words (split at spaces)\\n    words = s.split()\\n    \\n    # If there are no words, return 0\\n    if not words:\\n        return 0\\n    \\n    # Return the length of the last word\\n    return len(words[-1])\\n```\\n**Example Use Cases**\\n\\n```python\\nprint(length_of_last_word(\"Hello World\"))  # Output: 5\\nprint(length_of_last_word(\"   fly me   to   the moon  \"))  # Output: 4\\nprint(length_of_last_word(\"\"))  # Output: 0\\n```\\nThis solution works by first splitting the input string into a list of words using the `split()` method, which splits at spaces. If there are no words (i.e., the input string is empty), it returns 0. Otherwise, it returns the length of the last word in the list, accessed via `words[-1]`.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Solve the question with code in python\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Given a string \"\"\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/9j/4\n",
      " The image features a dark figure with black hair, wearing a black shirt. In this scene, there are many birds scattered around them, surrounding the person on all sides. Some birds can be seen flying or perched close to the person's body, while others are further away, creating an dramatic and dynamic visual effect.\n"
     ]
    }
   ],
   "source": [
    "# Adapted from OpenAI's Vision example \n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "# Ask the user for a path on the filesystem:\n",
    "path = \"itichi.jpg\"\n",
    "\n",
    "# Read the image and encode it to base64:\n",
    "base64_image = \"\"\n",
    "try:\n",
    "  image = open(path.replace(\"'\", \"\"), \"rb\").read()\n",
    "  base64_image = base64.b64encode(image).decode(\"utf-8\")\n",
    "  print(base64_image[:5])\n",
    "except:\n",
    "  print(\"Couldn't read the image. Make sure the path is correct and the file exists.\")\n",
    "  exit()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"This is a chat between a user and an assistant. The assistant is helping the user to describe an image.\",\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=1000,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content:\n",
    "    print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
